from bs4 import BeautifulSoup
import requests as req
import xlrd
import pandas as pd

link = 'https://www.avito.ru/rossiya/drugie_zhivotnye/amfibii-ASgBAgICAUSyA8oV?cd=1&p='

def goparse(link):
    times, titles, links = [],[],[]
    counter = 1
    while True:
        print(counter)
        res = req.get(link+str(counter))
        html = BeautifulSoup(res.text,'lxml')
        times += html.find_all('div',class_='date-text-2jSvU text-text-1PdBw text-size-s-1PUdo text-color-noaccent-bzEdI')
        links_a = html.find_all('a',class_='link-link-39EVK link-design-default-2sPEv title-root-395AQ iva-item-title-1Rmmj title-listRedesign-3RaU2 title-root_maxHeight-3obWc')
        page = html.find('span',class_='pagination-item-1WyVp pagination-item_arrow-Sd9ID')
        for a in links_a:
            titles.append(a.title)
            links.append(a['href'])

        if page == None:
            break
        counter+=1

    for i,time in enumerate(times):
        times[i]=time.text
    df = pd.DataFrame()
    df['Время'] = times
    df['Заголовки'] = titles
    df['Ссылки'] = links

    writer = pd.ExcelWriter('./habr.xlsx', engine = 'xlswriter')
    df.to_excel(writer,sheet_name='ЛИСТ1', index=False)

    writer.sheets['ЛИСТ1'].set_column('A:A',20)
    writer.sheets['ЛИСТ1'].set_column('B:B',100)
    writer.sheets['ЛИСТ1'].set_column('C:C ',50)

    writer.save()



goparse(link)
